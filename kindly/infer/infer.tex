\section{Inference}

An important innovation of \affe is its principal type inference.
We now formulate our inference algorithm
based on the $HM(X)$ framework~\citep{DBLP:journals/tapos/OderskySW99}.
$HM(X)$ presents a Hindley-Milner type system for a language
with qualified types where constraints are expressed in an arbitrary
constraint $X$. In particular, given some properties on the constraint system $X$,
$HM(X)$ ensures principal type inference.
We apply HM(X) to a concrete constraint language which we name $\CL$.
We adapt and extend its existing rules to support kind inference,
track linearity and handle borrows and regions. Finally, we
formulate an appropriate constraint solving algorithm for $\CL$.
In addition, our constraint solving algorithm simplifies constraints in a
principled way.
We first present various preliminary definitions
before showing our kind and type inference judgements
and our constraint solving algorithm.

\subsection{Preliminaries}

Unlike the syntax-directed version of our type system, knowing which elements
are input and output or our inference judgement is critical. In the rest
of this section, when presenting a new judgement
we will note in \textbf{bold} the input parameters. The rest will then be
output parameters.

\subsubsection{Usage environments}

% One novelty of our inference  judgement now
% returns a type environment, which we call ``usage environment'' and commonly
% note $\Sv$, to summarize how variables and borrows are used inside
% the expression.

In order to determine if a variable is used in an affine manner, we must track
its uses and the associated kinds. For instance, in the expression
$(x,x)$, $x$ is used twice. If $x$ is of type $\tau$, which is of kind $k$,
we must add the constraint $\Cleq{k}{\kun}$.
%
In order to infer such constraints, our inference judgement will not only
take an environment as parameter but also return an environment, which
we call ``usage environment'', and which summarize how variables and borrows
are used. Usage environments follow the exact same grammar
as normal environment. In order to distinguish them more easily,
we note them $\Sv$.

In \cref{sdtyping}, we used various relations to split environments in two, or
transform suspended bindings into borrow binding inside an environment.
These relations took as argument a constraint which is used to validate
the environment transformation.
In the context of inference, we define a new judgements which \emph{infers}
the constraints required.
\begin{itemize}
\item $\bsplit{C}{\Sv}{\bf{\Sv_1}}{\bf{\Sv_2}}$.
  Given two usage environments (inferred for two subexpressions, for instance)
  $\Sv_1$ and $\Sv_2$, we return $\Sv$, the merged environment, and $C$, a set
  of constraints that must be respected.
  This relation is total and non-ambiguous given $\Sv_1$ and $\Sv_2$
  and uses the same rules as the one presented in \cref{sdtyping:split}.
\item $\bregion{C}{\bf{x}}{\Sv}{\bf\Sv'}$.
  Given a usage environment $\Sv'$ and a variable name $x$, we return
  $\Sv$ where the borrow binding of $x$ in $\Sv'$, if it exists, is replaced by
  a suspended binding. We also return $C$, a set of constraints that must
  be respected.
  Again, the relation is total and non-ambiguous for any given $\Sv'$ and $x$,
  and uses the same rules as the one presented in \cref{sdtyping:regions}.
\end{itemize}

The relations used for syntax-directed typing can trivially be defined
in term of these new relations and constraint entailment.
All relations are fully described in \cref{typ:extra:envs}.

\subsubsection{Constraint normalization}

The HM(X) framework assumes the existence of a $\operatorname{normalize}$
function which takes a constraint $C$ and a substitution $\psi$ and returns a
simplified constraint $C'$,
and an updated substitution $\unif'$.
Normalization is supposed to return the ``best'' solution $(C',\unif')$, for
instance the most general unifier.
We detail the implementation
of the normalization function and its property in \cref{infer:solving}.
In the meantime, we simply
assume the existence of such a function for our constraint system.

\subsection{Kind inference}

We note $\inferK{(C,\unif)}{\bf{\E}}{\bf{\tau}}{k}$ when type $\tau$ has kind $k$
in environment $\E$ under constraints $C$ and unifier $\unif$.
$\E$ and $\tau$ are the input parameters of
our inference procedure.
We present the kind inference algorithm as a set of rules in
\cref{rules:kinding}.
Similar to the syntax-directed rules, higher-kinds are not generally supported
and can only appear by looking-up the kind scheme of a type constructor,
for use in the type application rule {\sc KApp}.
Type variables must be of a simple kind in rule {\sc KVar}.
Kind schemes are instantiated in the {\sc KVar} rules by creating
fresh kind variables and the associated substitution.
{\sc KArr} and {\sc KBorrow} simply returns the kind of the primitive
arrow and borrow types.
The $\operatorname{normalize}$ function is used every time several constraints
must be composed in order to simplify the constraint and return a most general
unifier.

\begin{figure}[ht]
  \centering
  \input{infer/kinds}
  \caption{Kind inference algorithm -- $\inferK{(C,\unif)}{\E}{\tau}{k}$}
  \label{rules:kinding}
\end{figure}



\subsection{Type inference}

We note $\inferW{\Sv}{(C,\unif)}{\bf{\E}}{\bf{e}}{\tau}$ when
$e$\ has type $\tau$ in $\E$ under the constraints $C$ and unifier $\unif$
with a usage environment $\Sv$. $\E$ and $e$ are the input parameters of our
inference algorithm.
We revisit the syntax-directed rules presented in \cref{sdtyping} to highlight the
novelties
of our inference algorithm and the differences with the syntax-directed
system.

\subsubsection{Environments and bindings}
\label{infer:envs}

In our syntax directed system presented in \cref{sdtyping}, we ensured
that linear variables are not discarded at the \emph{leafs}, through
the {\sc Var} rule. In the inference algorithm, we operate in the opposite
direction: we collect data from the leafs, and only enforce linearity
at \emph{binders}. This is reflected in the {\sc Var$_I$} and
{\sc Abs$_I$} rules presented in \cref{rule:infer:envs}.
Typing for variables is very similar to traditional (non-affine) ML
typing. The only difference is that we collect
the fact that $x$ was used with the scheme $\schm$ by returning
a usage environment $\Sv = \{ \bvar{x}{\schm} \}$.
%
This usage environment is in turn used at each binder to enforce proper
usage of linear variable via the $\Weaken$ property.
We demonstrate how this is achieved for lambda expressions
in the {\sc Abs$_I$} rule.
First, we typecheck the body of the lambda and obtain a usage
environment $\Sv_x$. Just like in the syntax directed,
we introduce the constraint
$\Cleq{\Sv\Sdel{x}}{\kvar}$ which properly accounts for captures in
the body of the lambda expression. We also introduce the constraint
$\Weaken_{\bvar{x}{\sigma}}(\Sv)$. If $x$ was used $e$, $x$ is present
in $\Sv$ and this constraint is empty. Otherwise, if $x$ is
\emph{not} present in $\Sv$, its type should not have a linear
kind, which is enforced by the constraints $\Cleq{\sigma}{\kaff_\infty}$.
The $\Weaken$ constraint is introduce at each binding point in the program
such as let-bindings and pattern matching.

Note again here the use of normalization on complex constraints to ensure
that the inference algorithm always return the simplest possible
constraints and unifiers.

\begin{figure}[!h]
  \begin{mathpar}
    { \Weaken_{\bvar{x}{\sigma}}(\Sv) =
      \begin{dcases}
        \Ctrue&\text{if } x\in\Sv\\
        \Cleq{\sigma}{\kaff_\infty}&\\
      \end{dcases}
    }
    \and
    \ruleIVar
    \and
    \ruleIAbs
  \end{mathpar}
  \caption{The {\sc Abs$_I$} and {\sc Var$_I$} rules}
  \label{rule:infer:envs}
\end{figure}


\subsubsection{Splitting and Regions}
\label{infer:split}
\label{infer:regions}


As noted previously, in our inference algorithm, we infer
usage environments which describes how variables are used. In
\cref{sdtyping}, we described the {\sc Pair} and {\sc Region} rules, and their
respective actions on the environment. We now see the inference version
of these rules in \cref{rule:infer:envrules}.
While the rules are quite similar to the original version, the usage
environment $\Sv$ is now an \emph{output} of the algorithm.
As such, we use the ``inference'' version of the relations on
environment,
$\bsplit{C}{\Sv}{\bf{\Sv_1}}{\bf{\Sv_2}}$ and $\bregion{C}{\bf{x}}{\Sv}{\bf\Sv'}$,
which returns the necessary constraints and
are total and non ambiguous for their input parameters ($\Sv_1, \Sv_2$ and $\Sv'$, respectively).
We then simply collect all the constraints and normalize them.

\begin{figure}[!h]
  \centering
  \begin{mathpar}
    \ruleIPair
    
    \ruleIRegion
  \end{mathpar}
  \caption{The {\sc Pair$_I$} and {\sc Region$_I$} rules}
  \label{rule:infer:envrules}
\end{figure}

\subsubsection{Generalization and constraints}


So far, constraints have only been composed of a list of kind inequalities.
The internal language of constraints used for inference is in fact
richer.
To illustrate this, we now show the inference rule for let-bindings
in \cref{rule:infer:let}.
This rule combines several ingredients previously seen:
since let expressions are binders, we use $\Weaken$ on the bound
identifier $x$. Since let-expressions contain
two subexpressions, so we use the environment splitting relation,
$\bsplit{C_s}{\Sv}{\Sv_1}{(\Sv_2 \Sdel{x})}$. We carefully remove the $x$ from
the left environment, since it is not available outside of the expression
$e_2$, and thus should not be part of the returned usage environment.

As per tradition in ML languages, generalization is performed
on let-bindings.
Following HM(X), we note $(C_\schm, \schm) = \generalize{C}{\E}{\tau}$
the pair of a constraint and a scheme resulting from
generalization. The definition is provided in \cref{rule:infer:let}.
The type scheme $\schm$ is created by quantifying over all the appropriate
free variables and the current constraints.
The generated constraint $C_\schm$ uses a new projection operator,
noted $\Cproj{\tvar}{D}$, which
allow the creation of local variables inside the constraints.
This allow to encapsulate all the quantified variables in the global constraints.
It also reflect the fact that there
should exists at least one solution for $C$ for the scheme to be valid.
\citet{DBLP:journals/tapos/OderskySW99} give a detailed account
on the projection operators in HM inference.

\begin{figure}[!h]
  \centering
  \begin{mathpar}
    \ruleILet

    {\generalize{C}{\E}{\tau} =
      (\Cproj{\Multi{\kvar},\Multi{\tvar}}{C},
      \forall \Multi{\kvar},\Multi{\tvar}.\qual{C}{\tau})

      \text{ where }

      \Multi{\kvar},\Multi{\tvar} = (\fv{\tau}\cup\fv{C})\setminus\fv{\E}
    }
  \end{mathpar}
  \caption{The {\sc Let$_I$} rule}
  \label{rule:infer:let}
\end{figure}

\subsection{Constraint solving}
\label{infer:solving}

\newcommand\A{\mathcal A}
\newcommand\SC{\mathcal S}

Before presenting our constraint solving algorithm,
we place ourselves in a more general context where kinds are either variables
or constants belonging to a total bounded lattice $(\mathcal L, \lk_\Lat)$ ie.,
a lattice which admits a total order and upper and lower bounds ($l^\top$ and $l^\bot$).
We note lattice elements $l$ and $\glb_i l_i$ (resp. $\lub_i l_i$)
the greatest lower bound (resp. least upper bound) in $\mathcal L$.
%
Let $\CL$ the set of constraints in this lattice.
The full grammar of constraints is shown in \cref{grammar:constraint}.
Constraints are made of kind inequalities, conjunctions and
projections, as shown previously, along with type unification
constraints. Since types might contain kinds (for instance, on the arrows),
type unification is oriented and noted $\leq$.

As before, entailment is noted $\entail{C}{D}$,
where $D$ is a consequence of the constraints $C$.
We say that $C$ and $D$ are equivalent, noted $C \equivC D$,
when $\entail{C}{D}$ and $\entail{D}{C}$.
The base rules for entailment are given in \cref{rules:entail}.
The rules for classic Herbrand unification and
projection operators are omitted for brevity (see
\citep{DBLP:journals/tapos/OderskySW99} for
details).

\begin{figure}[!h]
  \centering
  \begin{minipage}{0.32\linewidth}
    \begin{align*}
      C &::= \Cleq{\tau_1}{\tau_2} \\
        &\mid \Cleq{k_1}{k_2} \tag{Inequalities} \\
        &\mid C_1 \Cand C_2  \tag{Conjunction}\\
        &\mid \Cproj{\tvar}{C} 
        \mid \Cproj{\kvar}{C} \tag{Projection} 
    \end{align*}
    \caption{The constraint language}
    \label{grammar:constraint}
  \end{minipage}\hfill
  \begin{minipage}{0.64\linewidth}
    \begin{mathpar}
      \inferrule{}{\entail{}{\Cleq{k}{l^\top}}}
      \and
      \inferrule{}{\entail{}{\Cleq{l^\bot}{k}}}
      \and
      \inferrule
      {}{ \entail{}{\Cleq{\kvar}{\kvar}} }
      \and
      \inferrule
      { \forall i,\ \entail{C}{\Ceq{\tau_i}{\tau_i}}\\
      }
      { \entail{C}{\Cleq{\tapp{t}{(\tau_i)}}{\tapp{t}{(\tau'_i)}}} }
      \and
      \inferrule{l \lk_\Lat l'}{\entail{}{\Cleq{l}{l'}}}
      \and
      \inferrule
      { \entail{C}{\Cleq{\tau'_1}{\tau_1}}\\
        \entail{C}{\Cleq{\tau_2}{\tau'_2}}\\
        \entail{C}{\Cleq{k}{k'}}
      }
      { \entail{C}{\Cleq{\tau_1\tarr{k}\tau_2}{\tau'_1\tarr{k'}\tau'_2}} }
    \end{mathpar}
    \caption{Base entailment rules -- $\entail{C}{D}$ }
    \label{rules:entail}
  \end{minipage}
\end{figure}

We define the set of solved formed
$\mathcal S$ as the set of constraints $\CL$ quantified by $\equivC$.
We will show later that such constraints are in fact only composed of
kind inequalities, and thus correspond to the syntactic constraints
used in type and kind schemes.
%
We now define our normalization procedure, noted $\normalize{C_0}{\unif_0}$ where
$C_0\in \CL$ is a set of constraints and $\unif_0$ is a substitution.
It returns a constraint $C \in \mathcal S$ in
solved form and a unifier $\unif$.
The main idea of the algorithm is to first remove all the type equalities
by using regular Herbrand unification. After that, we only have
a set of inequalities among kinds, which we can consider as a relation.
We can then saturate the relation,
unify all kinds that are in the same equivalence classes to obtain
a most general unifier on kind variables,
remove all existentially quantified variables and
then minimize back the relation and apply various
simplification rules to make the resulting type easier to understand to users.

More precisely, we apply the following steps:
\begin{enumerate}
\item Solve all type equality constraints through Herband unification and
  gather all existential quantifications at the front of the constraint.
  We obtain a constraint $C^k = \exists \kvar_i,\ \Cleq{k_j}{k'_j}_j$ and
  a substitution $\unif_\tau$.
  
  We note $\mathcal R$ the relation $\Cleq{k_j}{k'_j}_j$,
  $\mathcal G$ the underlying directed graph and $V$ its vertices.

\item Saturate the lattice equalities in $\mathcal R$.
  
  More precisely, for each kind variable $\kvar \in V$,
  for each constant $l_i$ (resp. $l_j$) such that
  there is a path from $l_i$ to $\kvar$ (resp. from $\kvar$ to $l_j$) in $\mathcal G$,
  add an edge from $\lub l_i$ to $\kvar$
  (resp. from $\kvar$ to $\glb l_j$).
  This step is well defined since $\mathcal L$ is a bounded lattice
  and $\lub\emptyset$ and $\glb\emptyset$ are well defined.

  We also complement $\mathcal R$ with $(\leq)$ by adding an edge
  between related constants.
\item
  At this point, we can easily check for satisfiability: A constraint
  is satisfiable (in the given environment) if and only if,
  for any constants $l_1$ and $l_2$ such that
  there is a path from $l_1$ to $l_2$ in $\mathcal G$, then $l_1\lk_\Lat l_2$.
  If this is not the case, we return \textbf{fail}.
  
\item For each strongly connected component in $\mathcal G$, unify all its vertices and replace it by a representative.
  We note $\unif_k$ the substitution that replaces a kind variable by
  its representative.
  The representative of a strongly connected component $g$ can be determined as follows:
  \begin{itemize}
  \item If $g$ does not contain any constant, then the representative
    is a fresh kind variable.
  \item If $g$ contains exactly one constant, it is the representative.
  \item Otherwise, the initial constraint $C_0$ is not satisfiable.
  \end{itemize}
  Note that this step will also detect all unsatisfiable constraints.
\item Take the transitive closure of $\mathcal R$.
\item Remove all the vertices corresponding to the kind variables $\kvar_i$
  that are existentially quantified in $C^k$.
\item Take the transitive reduction of $\mathcal R$.
\item Remove the extremums of $\mathcal L$ and the edges of $(\leq)$
  from $\mathcal R$.
\item Return $C = \left\{ k \leq k' \mid k \operatorname{\mathcal R}k' \right\}$
  and $\unif =  \unif_\tau \meet \unif_k$.
\end{enumerate}

\TODO{Add example}

Our algorithm is complete, computes principal normal forms,
and already simplifies constraints significantly
(notably thanks to steps 6, 7 and 8).
It can be easily extended with further simplification phases.
In particular, our implementation and all the signatures presented in
\cref{motivation} use a variance-based simplification
where all covariant (resp. contravariant) variables are replaced by their
lower (resp. upper) bounds.
Remarkably, all the simplification mechanisms presented
here (including the variance-based one) are complete.
It is also possible to add ``best-effort'' simplification
rules which help reduce the size of inferred signatures even further
\citep{DBLP:conf/aplas/Simonet03}.
%
We now show that this algorithms is well-behaved with respect to entailment
and computes unique normal forms.

\begin{property}[Principal normal form]
  Normalization computes principal normal forms for $\CL$, i.e. 
  given a constraint $D\in\CL$, a substitution $\phi$ and
  $(C,\unif) = \normalize{D}{\phi}$,
  then $\phi\leq\unif$,
  $C \equivC \unif D$ and
  $\unif C = C$.
\end{property}

\begin{property}[Principal constraints]
  $\CL$ has the principal constraint property, i.e.
  for every $D\in\CL$, and a substitution $\unif$,
  either $D$ does not have a normal form, or it has
  a principal normal form.
\end{property}

\begin{property}[Regular constraint system]
  $\CL$ is regular, ie, for $x, x'$ two types or kinds,
  $\entail{}{\Ceq{x}{x'}}$ implies
  $\fv{x} = \fv{x'}$
\end{property}

The proofs are given in \cref{appendix:constraints}. These three properties
are sufficient to state that $HM(\CL)$ provides principal type inference.
However, we do not use HM(X) directly, but an extension with kind inference
and affine types and borrows.
We now show that HM(X)'s completeness and soundness theorems are still valid on
this extended system.

\subsection{Soundness and Principality}

We now show that our extended inference algorithm still satisfies the soundness
and completeness properties of HM(X). This is achieved by extending
the original proofs.
%
The first theorem states that our inference algorithm is sound
with respect to the syntax directed type system.

\begin{theorem}[Soundness of inference]
  Given a type environment $\E$ and a term $e$,\\
  if $\inferW{\Sv}{(C,\unif)}{\E}{e}{\tau}$
  then $\inferS{C}{\unif\Sv}{e}{\tau}$, $\unif C = C$ and $\unif \tau = \tau$.
\end{theorem}

Note here that the syntax-directed derivation holds with the usage environment $\Sv$ instead of the originally provided environment $\E$. Indeed,
$\E$ does not contain suspended and borrow bindings, since those
are discovered on the fly and recorded in $\Sv$.

The second theorem states that our algorithm is complete: for any given
syntax directed typing derivation, our inference algorithm can find
a derivation that gives a type at least as general.
For this, we need first to provide a few additional definitions.

\begin{definition}[More general unifier]
  Given a set of variable $U$ and $\unif$, $\unif'$ and $\phi$
  substitutions. \\
  Then
  $\unif \leq^{\phi}_{U} \unif'$ iff $(\phi \circ \unif)|_{U} = \unif'|_U$.
\end{definition}

\begin{definition}[Instance relation]
  Given a constraints $C$ and two schemes
  $\schm = \forall \Multi\tvar. \qual{D}{\tau}$ and
  $\schm' = \forall \Multi\tvar'. \qual{D'}{\tau'} $.
  Then $\entail{C}{\schm \preceq \schm'}$
  iff $\entail{C}{\subst{\tvar}{\tau''} D}$
  and $\entail{C\Cand D'}{\Cleq{\subst{\tvar}{\tau''}\tau}{\tau'}}$
\end{definition}

\begin{definition}[Flattened Environment]
A flattened environment,
noted $\Eflat\E$, is the environment
where all the binders are replace by normal ones. More formally:
\begin{align*}
  \Eflat\E
  &= \left\{ \bvar{x}{\tau} \mid
    \bvar{x}{\tau}\in\E
    \vee \bvar{\borrow{x}}{\borrowty{k}{\tau}}\in\E
    \vee \svar{x}{\tau}^n\in\E
    \right\} \cup \left\{ \bvar{\tvar}{k} \mid \bvar{\tvar}{k}\in\E \right\}
\end{align*}
\end{definition}


We can then state the completeness theorem.

\begin{theorem}[Completeness]
  Let $\inferS{C'}{\unif'\E}{e}{\schm'}$ a typing derivation,
  then $\inferW{\Sv}{(C,\unif)}{\Eflat\E}{e}{\tau}$
  for some substitution $\unif$, constraint $C$ and type $\tau$ such
  that
  \begin{align*}
    (C_\schm,\schm) &= \generalize{C}{\unif\E}{\tau}
    &\unif &\leq^{\phi}_{\fv{\E}} \unif'
    &\entail{C'&}{\phi C}
    &\entail{C'&}{\phi \schm \preceq \schm'}
    % &( C, \schm, \unif) &\leq (C',\schm',\unif')
  \end{align*}
\end{theorem}

The proofs are given in \cref{appendix:infer}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
